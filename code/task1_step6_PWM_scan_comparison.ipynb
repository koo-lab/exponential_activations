{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook compares PWM scans vs filter scans of a CNN using relu and exponential activations.\n",
    "\n",
    "\n",
    "Figures generated from this notebook include:\n",
    "- Extended Data Fig. 1c \n",
    "- Extended Data Fig. 1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, accuracy_score, roc_auc_score\n",
    "\n",
    "from six.moves import cPickle\n",
    "from tensorflow import keras\n",
    "import helper\n",
    "from tfomics import utils, metrics\n",
    "\n",
    "# plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "def interpretability_performance(X, score, X_model, buffer=20):\n",
    "    \"\"\"Function to calculate the localization performance for a motif scan. Buffer is added\n",
    "       to deal with motif positions within convolutional filters.\"\"\"\n",
    "    \n",
    "    pr_score = []\n",
    "    roc_score = []\n",
    "    for j, gs in enumerate(score):\n",
    "\n",
    "        # calculate information of ground truth\n",
    "        gt_info = np.log2(4) + np.sum(X_model[j]*np.log2(X_model[j]+1e-10),axis=0)\n",
    "\n",
    "        # set label if information is greater than 0\n",
    "        label = np.zeros(gt_info.shape)\n",
    "        label[gt_info > 0.01] = 1\n",
    "        \n",
    "        # extend labels\n",
    "        box_filter = np.ones(buffer)\n",
    "        pad_left = int(buffer/2)\n",
    "        pad_right = buffer - pad_left\n",
    "        x_pad = np.concatenate([np.zeros(pad_left), label, np.zeros(pad_right)], axis=0) \n",
    "        new_label = []\n",
    "        for n in range(L):\n",
    "            new_label.append(np.sum(x_pad[range(n,n+buffer)] * box_filter))            \n",
    "        new_label = np.array(new_label)\n",
    "        new_label[new_label > 0.01] = 1\n",
    "\n",
    "        # get positive instance \n",
    "        pos_instance = []\n",
    "        index = 0\n",
    "        status = True\n",
    "        while status:\n",
    "            s = np.where(new_label[index:] == 1)[0]\n",
    "            if any(list(s)):\n",
    "                start = index + s[0]\n",
    "            else:\n",
    "                status = False\n",
    "            e = np.where(new_label[index+start:] == 0)[0]\n",
    "            if any(list(e)):\n",
    "                end = index + start + e[0]\n",
    "                pos_instance.append(np.max(gs[start:end]))\n",
    "                index = end\n",
    "            else:\n",
    "                status = False\n",
    "        \n",
    "        # get negative instance\n",
    "        neg_instance = []\n",
    "        index = 0\n",
    "        status = True\n",
    "        while status:\n",
    "            s = np.where(new_label[index:] == 0)[0]\n",
    "            if any(list(s)):\n",
    "                start = index + s[0]\n",
    "            else:\n",
    "                status = False\n",
    "            e = np.where(new_label[index+start:] == 1)[0]\n",
    "            if any(list(e)):\n",
    "                end = index + start + e[0]\n",
    "                neg_instance.append(np.max(gs[start:end]))\n",
    "                index = end\n",
    "            else:\n",
    "                end = L\n",
    "                neg_instance.append(np.max(gs[start:end]))\n",
    "                status = False\n",
    "\n",
    "        vals = np.concatenate([pos_instance, neg_instance])\n",
    "        labels = np.concatenate([np.ones(len(pos_instance)), np.zeros(len(neg_instance))])\n",
    "\n",
    "        # precision recall metric\n",
    "        precision, recall, thresholds = precision_recall_curve(labels, vals)\n",
    "        pr_score.append(auc(recall, precision))\n",
    "\n",
    "        # roc curve\n",
    "        fpr, tpr, thresholds = roc_curve(labels, vals)\n",
    "        roc_score.append(auc(fpr, tpr))\n",
    "\n",
    "    roc_score = np.array(roc_score)\n",
    "    pr_score = np.array(pr_score)\n",
    "\n",
    "    return roc_score, pr_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = '../data/synthetic_dataset.h5'\n",
    "data = helper.load_data(data_path)\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = data\n",
    "\n",
    "# load ground truth values\n",
    "test_model = helper.load_synthetic_models(data_path, dataset='test')\n",
    "X = x_test\n",
    "X_model = test_model\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ground truth motifs from JASPAR database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaspar_motifs(file_path):\n",
    "    def get_motif(f):\n",
    "        line = f.readline()\n",
    "        name = line.strip().split()[1]\n",
    "        pfm = []\n",
    "        for i in range(4):\n",
    "            line = f.readline()\n",
    "            if len(line.split()[1]) > 1:\n",
    "                pfm.append(np.asarray(np.hstack([line.split()[1][1:], line.split()[2:-1]]), dtype=float))\n",
    "            else:\n",
    "                pfm.append(np.asarray(line.split()[2:-1], dtype=float))\n",
    "        pfm = np.vstack(pfm)\n",
    "        sum_pfm = np.sum(pfm, axis=0)\n",
    "        pwm = pfm/np.outer(np.ones(4), sum_pfm)\n",
    "        line = f.readline()\n",
    "        return name, pwm\n",
    "\n",
    "    num_lines = sum(1 for line in open(file_path))\n",
    "    num_motifs = int(num_lines/6)\n",
    "\n",
    "    f = open(file_path)\n",
    "    tf_names = []\n",
    "    tf_motifs = []\n",
    "    for i in range(num_motifs):\n",
    "        name, pwm = get_motif(f)\n",
    "        tf_names.append(name)\n",
    "        tf_motifs.append(pwm)\n",
    "\n",
    "    return tf_motifs, tf_names\n",
    "\n",
    "# parse JASPAR motifs\n",
    "savepath = '../data'\n",
    "file_path = os.path.join(savepath, 'pfm_vertebrates.txt')\n",
    "motif_set, motif_names = get_jaspar_motifs(file_path)\n",
    "\n",
    "# get a subset of core motifs \n",
    "core_names = ['Arid3a', 'CEBPB', 'FOSL1', 'Gabpa', 'MAFK', 'MAX', \n",
    "              'MEF2A', 'NFYB', 'SP1', 'SRF', 'STAT1', 'YY1']\n",
    "strand_motifs = []\n",
    "core_index = []\n",
    "for name in core_names:\n",
    "    strand_motifs.append(motif_set[motif_names.index(name)])\n",
    "    core_index.append(motif_names.index(name))\n",
    "\n",
    "# generate reverse compliments\n",
    "core_motifs = []\n",
    "for pwm in strand_motifs:\n",
    "    core_motifs.append(pwm)\n",
    "    reverse = pwm[:,::-1]\n",
    "    core_motifs.append(reverse[::-1,:]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate scans with JASPAR motifs and PWM scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, L, A = X.shape\n",
    "num_motifs = len(core_motifs)\n",
    "\n",
    "fmap_all = []\n",
    "fmap_pwm = []\n",
    "for n, x in enumerate(X):\n",
    "    if np.mod(n+1,250) == 0:\n",
    "        print(\"%d out of %d\"%(n+1, N))\n",
    "    fmap_motifs = []\n",
    "    fmap_motifs_pwm = []\n",
    "    for i in range(num_motifs):\n",
    "        \n",
    "        # get the motif position probability matrix\n",
    "        ppm = core_motifs[i]\n",
    "        ppm = ppm.T\n",
    "\n",
    "        # calculate the PWM\n",
    "        pwm = np.log2(core_motifs[i]/(np.ones(core_motifs[i].shape)/4)+1e-10)\n",
    "        pwm = pwm.T\n",
    "\n",
    "        # zero-pad to get same shape as original sequence\n",
    "        M = ppm.shape[0]\n",
    "        num_pad = M\n",
    "        pad_left = int(num_pad/2)\n",
    "        pad_right = num_pad - pad_left\n",
    "        x_pad = np.concatenate([np.zeros((pad_left, 4)), x, np.zeros((pad_right,4))], axis=0) \n",
    "        \n",
    "        # calculate motif scan\n",
    "        fmap = []\n",
    "        for n in range(L):\n",
    "            fmap.append(np.sum(x_pad[range(n,n+M),:] * ppm))            \n",
    "        fmap_motifs.append(fmap)\n",
    "        \n",
    "\n",
    "        # calculate PWM scan\n",
    "        fmap = []\n",
    "        for n in range(L):\n",
    "            fmap.append(np.sum(x_pad[range(n,n+M),:] * pwm))            \n",
    "        fmap_motifs_pwm.append(fmap)\n",
    "        \n",
    "        \n",
    "    fmap_all.append(fmap_motifs)\n",
    "    fmap_pwm.append(fmap_motifs_pwm)\n",
    "fmap_all = np.array(fmap_all)\n",
    "fmap_pwm = np.array(fmap_pwm)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print localization performance for motif scan and pwm scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.max(fmap_all, axis=1)\n",
    "ppm_roc_score, ppm_pr_score = interpretability_performance(X, score, X_model, buffer=10)\n",
    "print('Motif scan results')\n",
    "print(\"AUROC: %.4f+/-%.4f\"%(np.nanmean(ppm_roc_score), np.nanstd(ppm_roc_score)))\n",
    "print(\"AUPR: %.4f+/-%.4f\"%(np.nanmean(ppm_pr_score), np.nanstd(ppm_pr_score)))\n",
    "\n",
    "score = np.max(fmap_pwm, axis=1)\n",
    "pwm_roc_score, pwm_pr_score = interpretability_performance(X, score, X_model, buffer=10)\n",
    "print('PWM results')\n",
    "print(\"AUROC: %.4f+/-%.4f\"%(np.nanmean(pwm_roc_score), np.nanstd(pwm_roc_score)))\n",
    "print(\"AUPR: %.4f+/-%.4f\"%(np.nanmean(pwm_pr_score), np.nanstd(pwm_pr_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results for scans\n",
    "results_path = os.path.join('../results', 'task1')\n",
    "with open(os.path.join(results_path, 'pwm_scans.pickle'), 'wb') as f:\n",
    "    cPickle.dump(pwm_roc_score, f)\n",
    "    cPickle.dump(pwm_pr_score, f)    \n",
    "    cPickle.dump(ppm_roc_score, f)\n",
    "    cPickle.dump(ppm_pr_score, f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get filter scans for first convolutional layer filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "num_trials = 10\n",
    "model_names = ['cnn-deep']\n",
    "activations = ['exponential', 'relu']\n",
    "\n",
    "results_path = os.path.join('../results', 'task1')\n",
    "params_path = os.path.join(results_path, 'model_params')\n",
    "\n",
    "results = {}\n",
    "for model_name in model_names:\n",
    "    for activation in activations:\n",
    "        results[model_name+'_'+activation] = []\n",
    "        for trial in range(num_trials):\n",
    "            keras.backend.clear_session()\n",
    "            \n",
    "            # load model\n",
    "            model = helper.load_model(model_name, \n",
    "                                            activation=activation, \n",
    "                                            input_shape=200)\n",
    "            name = model_name+'_'+activation+'_'+str(trial)\n",
    "            print('model: ' + name)\n",
    "\n",
    "            weights_path = os.path.join(params_path, name+'.hdf5')\n",
    "            model.load_weights(weights_path)            \n",
    "            \n",
    "            intermediate = keras.Model(inputs=model.inputs, outputs=model.layers[3].output)\n",
    "            results[model_name+'_'+activation].append(intermediate.predict(X))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filter scans\n",
    "with open(os.path.join(results_path, 'fmaps.pickle'), 'wb') as f:\n",
    "    cPickle.dump(results, f, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot scan comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path = utils.make_directory(results_path, 'pwm_comparison')\n",
    "\n",
    "model_name = 'cnn-deep'\n",
    "fmap_deep_relu = results[model_name+'_relu'][0]\n",
    "fmap_deep_exp = results[model_name+'_exponential'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "ax = plt.subplot(3,2,1)\n",
    "ax.plot(np.maximum(fmap_all[index].T, 0));\n",
    "ax.set_xticklabels([])\n",
    "plt.title('Ground truth', fontsize=12)\n",
    "plt.ylabel('Motif scan', fontsize=12)\n",
    "#plt.figure()\n",
    "#plt.plot(fmap_deep_relu[index]);\n",
    "\n",
    "ax = plt.subplot(3,2,2)\n",
    "\n",
    "threshold = np.exp(-10)\n",
    "ax.plot(np.maximum(fmap_deep_relu[index], threshold));\n",
    "ax.set_xticklabels([])\n",
    "plt.title('CNN', fontsize=12)\n",
    "plt.ylabel('Relu', fontsize=12)\n",
    "\n",
    "\n",
    "ax = plt.subplot(3,2,3)\n",
    "ax.plot(np.maximum(fmap_pwm[index].T, 0));\n",
    "plt.ylabel('PWM scan', fontsize=12)\n",
    "ax.set_xticklabels([])\n",
    "ax2 = ax.twinx()\n",
    "#plt.ylabel('PWM', fontsize=12)\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3,2,4)\n",
    "threshold = np.exp(4)\n",
    "ax.plot(np.maximum(fmap_deep_exp[index], threshold));\n",
    "ax.set_xticklabels([])\n",
    "plt.ylabel('Exp', fontsize=12)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "\n",
    "ax = plt.subplot(3,2,5)\n",
    "buffer = 1\n",
    "\n",
    "# calculate information of ground truth\n",
    "gt_info = np.log2(4) + np.sum(X_model[index]*np.log2(X_model[index]+1e-10),axis=0)\n",
    "\n",
    "# set label if information is greater than 0\n",
    "label = np.zeros(gt_info.shape)\n",
    "label[gt_info > 0.01] = 1\n",
    "\n",
    "# extend labels\n",
    "box_filter = np.ones(buffer)\n",
    "pad_left = int(buffer/2)\n",
    "pad_right = buffer - pad_left\n",
    "x_pad = np.concatenate([np.zeros(pad_left), label, np.zeros(pad_right)], axis=0) \n",
    "new_label = []\n",
    "for n in range(L):\n",
    "    new_label.append(np.sum(x_pad[range(n,n+buffer)] * box_filter))            \n",
    "new_label = np.array(new_label)\n",
    "new_label[new_label > 0.01] = 1\n",
    "plt.ylabel('Information', fontsize=12)\n",
    "\n",
    "ax.plot(gt_info);\n",
    "\n",
    "ax = plt.subplot(3,2,6)\n",
    "buffer = 1\n",
    "\n",
    "# calculate information of ground truth\n",
    "gt_info = np.log2(4) + np.sum(X_model[index]*np.log2(X_model[index]+1e-10),axis=0)\n",
    "\n",
    "# set label if information is greater than 0\n",
    "label = np.zeros(gt_info.shape)\n",
    "label[gt_info > 0.01] = 1\n",
    "\n",
    "# extend labels\n",
    "box_filter = np.ones(buffer)\n",
    "pad_left = int(buffer/2)\n",
    "pad_right = buffer - pad_left\n",
    "x_pad = np.concatenate([np.zeros(pad_left), label, np.zeros(pad_right)], axis=0) \n",
    "new_label = []\n",
    "for n in range(L):\n",
    "    new_label.append(np.sum(x_pad[range(n,n+buffer)] * box_filter))            \n",
    "new_label = np.array(new_label)\n",
    "new_label[new_label > 0.01] = 1\n",
    "plt.ylabel('Information', fontsize=12)\n",
    "\n",
    "ax.plot(gt_info);\n",
    "ax2 = ax.twinx()\n",
    "plt.ylabel('Ground\\ntruth', fontsize=12)\n",
    "plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot scan comparisons for many examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_plots = 20\n",
    "for index in indices[:num_plots]:\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "    ax = plt.subplot(3,2,1)\n",
    "    ax.plot(np.maximum(fmap_all[index].T, 0));\n",
    "    ax.set_xticklabels([])\n",
    "    plt.title('Ground truth', fontsize=12)\n",
    "    plt.ylabel('Motif scan', fontsize=12)\n",
    "    #plt.figure()\n",
    "    #plt.plot(fmap_deep_relu[index]);\n",
    "\n",
    "    ax = plt.subplot(3,2,2)\n",
    "\n",
    "    threshold = np.exp(-10)\n",
    "    ax.plot(np.maximum(fmap_deep_relu[index], threshold));\n",
    "    ax.set_xticklabels([])\n",
    "    plt.title('CNN', fontsize=12)\n",
    "    plt.ylabel('Relu', fontsize=12)\n",
    "\n",
    "\n",
    "    ax = plt.subplot(3,2,3)\n",
    "    ax.plot(np.maximum(fmap_pwm[index].T, 0));\n",
    "    plt.ylabel('PWM scan', fontsize=12)\n",
    "    ax.set_xticklabels([])\n",
    "    ax2 = ax.twinx()\n",
    "    #plt.ylabel('PWM', fontsize=12)\n",
    "    plt.yticks([])\n",
    "\n",
    "    ax = plt.subplot(3,2,4)\n",
    "    threshold = np.exp(4)\n",
    "    ax.plot(np.maximum(fmap_deep_exp[index], threshold));\n",
    "    ax.set_xticklabels([])\n",
    "    plt.ylabel('Exp', fontsize=12)\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "\n",
    "    ax = plt.subplot(3,2,5)\n",
    "    buffer = 1\n",
    "\n",
    "    # calculate information of ground truth\n",
    "    gt_info = np.log2(4) + np.sum(X_model[index]*np.log2(X_model[index]+1e-10),axis=0)\n",
    "\n",
    "    # set label if information is greater than 0\n",
    "    label = np.zeros(gt_info.shape)\n",
    "    label[gt_info > 0.01] = 1\n",
    "\n",
    "    # extend labels\n",
    "    box_filter = np.ones(buffer)\n",
    "    pad_left = int(buffer/2)\n",
    "    pad_right = buffer - pad_left\n",
    "    x_pad = np.concatenate([np.zeros(pad_left), label, np.zeros(pad_right)], axis=0) \n",
    "    new_label = []\n",
    "    for n in range(L):\n",
    "        new_label.append(np.sum(x_pad[range(n,n+buffer)] * box_filter))            \n",
    "    new_label = np.array(new_label)\n",
    "    new_label[new_label > 0.01] = 1\n",
    "    plt.ylabel('Information', fontsize=12)\n",
    "\n",
    "    ax.plot(gt_info);\n",
    "\n",
    "    ax = plt.subplot(3,2,6)\n",
    "    buffer = 1\n",
    "\n",
    "    # calculate information of ground truth\n",
    "    gt_info = np.log2(4) + np.sum(X_model[index]*np.log2(X_model[index]+1e-10),axis=0)\n",
    "\n",
    "    # set label if information is greater than 0\n",
    "    label = np.zeros(gt_info.shape)\n",
    "    label[gt_info > 0.01] = 1\n",
    "\n",
    "    # extend labels\n",
    "    box_filter = np.ones(buffer)\n",
    "    pad_left = int(buffer/2)\n",
    "    pad_right = buffer - pad_left\n",
    "    x_pad = np.concatenate([np.zeros(pad_left), label, np.zeros(pad_right)], axis=0) \n",
    "    new_label = []\n",
    "    for n in range(L):\n",
    "        new_label.append(np.sum(x_pad[range(n,n+buffer)] * box_filter))            \n",
    "    new_label = np.array(new_label)\n",
    "    new_label[new_label > 0.01] = 1\n",
    "    plt.ylabel('Information', fontsize=12)\n",
    "\n",
    "    ax.plot(gt_info);\n",
    "    ax2 = ax.twinx()\n",
    "    plt.ylabel('Ground\\ntruth', fontsize=12)\n",
    "    plt.yticks([])\n",
    "\n",
    "    outfile = os.path.join(plot_path, 'pwm_comparison_'+str(index))\n",
    "    fig.savefig(outfile, format='pdf', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
